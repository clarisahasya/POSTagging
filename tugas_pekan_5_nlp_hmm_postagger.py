# -*- coding: utf-8 -*-
"""Tugas Pekan 5 - NLP - HMM Postagger.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IYtXwoEmvGNWGkHOZVveEl-lgWEEOfEr

# **POSTagging : HMM-Viterbi**

---

Clarisa Hasya Y - 1301174256
"""

import pandas as pd

"""**Read File Data Train TSV**"""

df = pd.read_csv("dataset/train.01.tsv",sep="\t", header=None)
df = df.astype(str)

# df.head()

"""**Inisialisasi Tagset**"""

count = 0
i = 1
j = 0
tag_count = {} # dictionary untuk menyimpan frekuensi tag
tag_count['<start>'] = 0
tags = []  # list untuk menyimpan tag per kata
tags.append('<start>') 
# tags = {0:'<start>'}
tagset = {} # dictionary untuk menyimpan tagset
for index, row in df.iterrows():
    word = row[0].lower()
    tag = row[1]    
    key = (i,str(tag)) 
    if word != 'nan':
        if key not in tags:        
            if word == '.' and tag == 'Z':
                tags.append(str(tag))
                tags.append('<start>')
                tag_count['<start>'] += 1
                i += 2
            else:
                tags.append(str(tag))
                i += 1

        if tag in tag_count:
            tag_count[tag] += 1
        else:
            tag_count[tag] = 1

    if word == '.' and tag == 'Z':
        count += 1
    if count == 50:
        break

for t in tag_count:
    tagset[j] = t
    j += 1

tags.pop()
# print(tags)

# print(tag_count)
print('Tagset')
print(tagset)
print('===============================================================================================')

"""**Inisialisasi Vocabulary**"""

vocabs = {} # dictionary untuk menyimpan vocab
vocab_count = {} # dictionary untuk menyimpan frekuensi vocab
count = 0
i = 0
for index, row in df.iterrows():
    word = row[0].lower()
    tag = row[1]
    key = (i,str(word)) 
    if word != 'nan':
        if key not in vocabs:
            vocabs[i] = str(word)
            i += 1

        if word in vocab_count:
            vocab_count[word] += 1
        else:
            vocab_count[word] = 1

    if word == '.' and tag == 'Z':
        count += 1
    if count == 50:
        break

# print(vocabs)

# print(vocab_count)

"""**Inisialisasi Emission Probability**"""

emission_count = {} # dictionary untuk menyimpan frekuensi semua kemungkinan emission
count = 0
for index, row in df.iterrows():
    word = row[0].lower()
    tag = row[1]
    # key = (word,tag)
    key = tag,word
    # print(key)
    if word != 'nan':
        if key in emission_count:
            emission_count[key] = emission_count[key] + 1
        else:
            emission_count[key] = 1
        
    if word == '.' and tag == 'Z':
        count += 1
    if count == 50:
        break

for vocab in vocab_count:
    for tag in tag_count:
        key = (tag,vocab)
        if key not in emission_count: # jika kombinasi vocab dan tag belom ada dari data train, maka akan di assign 0
            emission_count[key] = 0

emission_prob = {} # dictionary untuk menyimpan emission probabilitas
for key in emission_count:
    tag, vocab = key
    emission_prob[key] = emission_count[key] / tag_count[tag]

print('Emission Probability')
print(emission_prob)
print('===============================================================================================')

"""**Inisialisasi Transition Probability**"""

transition_count = {} # dictionary untuk menyimpan frekuensi semua kemungkinan transition
count = 0

for i in range(1, len(tags)):
    curr_tag = (tags[i-1], tags[i])
    if curr_tag in transition_count:
        transition_count[curr_tag] += 1
    else:
        transition_count[curr_tag] = 1

for i in tag_count:
    for j in tag_count:
        if (i,j) not in transition_count: # jika kombinasi tag belom ada dari data train, maka akan di assign 0
            transition_count[(i,j)] = 0

# print(transition_count)

transition_prob = {} # dictionary untuk menyimpan transition probabilitas
for key in transition_count:
    a, b = key # a=ti-1  b=ti
    transition_prob[key] = transition_count[key] / tag_count[a]

print('Transition Probability')
print(transition_prob)
print('===============================================================================================')

"""**Fungsi Viterbi**"""

def viterbi(trans_prob, emission_prob, tokens):
    # create a path probability matrix viterbi[N,T]
    # N: banyaknya state
    # T: jumlah token

    T, N = len(tokens)+1, len(tagset) # token ditambah satu untuk start
    new_tokens = ['<s>'] + tokens
    print('T=',T,',N=',N)
    print('token:',new_tokens)
    viterbi_mat = [[0 for x in range(T)] for y in range(N)] 
    print('matriks viterbi setelah di-create:',viterbi_mat)
    print('baris adalah tag/state dan kolom adalah token\n')
    # create backpointers matrix
    backpointers = [[0 for x in range(T)] for y in range(N)] 

    # initial probability distribution over states (phi)
    # transition probability dengan previous state adalah <start>
    phi = {}
    for i in range (1,len(tagset)):
        phi[tagset[i]] = transition_prob[('<start>',tagset[i])]
                    
    # initialization
    # urutan index state sesuai dengan index di dictionary tags{}
    # inisialisasi dimulai dari state ke-1, state ke-0 sudah pasti <start>
    viterbi_mat[0][0] = 1.0 # untuk token <s>, tag = <start>
    for s in range(1,N):
        viterbi_mat[s][1] = phi[tagset[s]] * emission_prob[(tagset[s],new_tokens[1])]
        backpointers[s][1] = 0

    print('viterbi mat setelah inisialisasi, proses token pertama ',new_tokens[1],':')
    print(viterbi_mat)
    print('\n')

    # recursion step
    for t in range(2,T):
        print('token ke ',t,':',new_tokens[t])
        for s in range(1,N):
            # get max viterbi from previous transition
            max_prev_transition = 0.0
            max_state = 0
            print('menghitung nilai viterbi untuk state:',tagset[s])
            for i in range(1,N):                
                #selain transisi dari tag <start>, range mulai dari indeks 1
                temp_transition = viterbi_mat[i][t-1] * transition_prob[(tagset[i],tagset[s])]
                print('t-1 = ',t-1)   
                print('current calculation ',tagset[i],'i:',i,'=',viterbi_mat[i][t-1],'*',transition_prob[(tagset[i],tagset[s])],'=',temp_transition)           
                if temp_transition > max_prev_transition:
                    max_prev_transition = temp_transition
                    max_state = i
            viterbi_mat[s][t] = max_prev_transition * emission_prob[(tagset[s],new_tokens[t])]
            backpointers[s][t] = max_state
        print('viterbi mat setelah proses token: ',new_tokens[t])
        print(viterbi_mat)
        print('\n')

    

    # terminasi
    # get max probability in last column
    max_last_prob = 0.0
    best_last_tag = ''
    idx_best_last_tag = 0
    for i in range (1,N):
        if viterbi_mat[i][T-1] > max_last_prob:
            max_last_prob = viterbi_mat[i][T-1]
            best_last_tag = tagset[i]
            idx_best_last_tag = i
    print('last token = ',new_tokens[T-1],',tag = ',best_last_tag,',max_last_prob =',max_last_prob)

    best_path = []
    best_path.append(idx_best_last_tag)
    for i in range(T-1,1,-1):
        best_prev_tag = backpointers[idx_best_last_tag][i]
        print('best_prev_tag=',best_prev_tag)
        best_path.append(best_prev_tag)
    # reverse the order
    best_path = best_path[::-1]
    
    return viterbi_mat, best_path

"""**Read File Data Test TSV**"""

dt = pd.read_csv("dataset/test_sentences.tsv",sep="\t", header=None)
dt = dt.astype(str)

# dt.head()

tmpp, tempp = [] , [] 
testing_sentences, testing_tags = [] , []

for index, row in dt.iterrows():   
    wordd = row[0].lower()
    tagg = row[1]
    if wordd != 'nan':
        tmpp.append(wordd)
        tempp.append(tagg)
        if wordd == '.' :
            testing_sentences.append(tmpp)
            testing_tags.append(tempp)
            tmpp = []
            tempp = []

# print(testing_sentences)

# print(testing_tags)

"""**Testing**"""

path =[]
for sentence in testing_sentences: # dilakukan pengujian dari data test per kalimat yang sudah berbentuk token
    viterbi_mat, best_path =  viterbi(transition_prob,emission_prob,sentence)
    path.append(best_path)

# print(viterbi_mat)

# print(path)

"""Actual POSTag"""

test_tags =[]
for t in testing_tags:
    test_tags += t

print('===============================================================================================')
print('Actual POSTag')
print(test_tags)
print('===============================================================================================')

"""Prediction POSTag"""

pred_tags = []
for best in path:
    for tag in best:
        pred_tags.append(tagset[tag])
print('Prediction POSTag')
print(pred_tags)
print('===============================================================================================')

"""**Accuracy HMM Viterbi**"""

for i in range(len(test_tags)):
    if test_tags[i] == pred_tags[i]:
        count += 1

print('===============================================================================================')
print('Accuracy HMM Viterbi : ', count/len(test_tags))
print('===============================================================================================')